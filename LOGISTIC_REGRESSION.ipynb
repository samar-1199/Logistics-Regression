{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.**What is Logistic Regression, and how does it differ from Linear Regression"
      ],
      "metadata": {
        "id": "YFD3pLPtAQek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Linear Regression is a machine learning algorithm based on supervised regression algorithm. Regression models a target prediction value based on independent variables. It is mostly used for finding out the relationship between variables and forecasting. Different regression models differ based on the kind of relationship between the dependent and independent variables, they are considering and the number of independent variables being used. Logistic regression is basically a supervised classification algorithm. In a classification problem, the target variable(or output), y, can take only discrete values for a given set of features(or inputs), X.\n",
        "\n"
      ],
      "metadata": {
        "id": "BoIIpipDCLxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.**' What is the mathematical equation of Logistic Regression"
      ],
      "metadata": {
        "id": "wfMI9qKKCMOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  p(X;b,w)=\n",
        "1+e\n",
        "w⋅X+b\n",
        "\n",
        "e\n",
        "w⋅X+b\n",
        "\n",
        "​\n",
        " =\n",
        "1+e\n",
        "−w⋅X+b\n"
      ],
      "metadata": {
        "id": "3WjADUjDJKw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.**Why do we use the Sigmoid function in Logistic Regression"
      ],
      "metadata": {
        "id": "TJW9KocNCUbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Sigmoid is a mathematical function that maps any real-valued number into a value between 0 and 1. Its characteristic “S”-shaped curve makes it particularly useful in scenarios where we need to convert outputs into probabilities. This function is often called the logistic function"
      ],
      "metadata": {
        "id": "Lsw6R_1jCdko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.**What is the cost function of Logistic Regression"
      ],
      "metadata": {
        "id": "ZUm1sQ2lCd7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  A cost function is a mathematical function that calculates the difference between the target actual values (ground truth) and the values predicted by the model. A function that assesses a machine learning model’s performance also referred to as a loss function or objective function. Usually, the objective of a machine learning algorithm is to reduce the error or output of cost function."
      ],
      "metadata": {
        "id": "QQ1y5_vtDPmf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.** What is Regularization in Logistic Regression? Why is it needed"
      ],
      "metadata": {
        "id": "Nzi8ALZEDQGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Regularization is a technique used in machine learning to prevent overfitting. Overfitting happens when a model learns the training data too well, including the noise and outliers, which causes it to perform poorly on new data. In simple terms, regularization adds a penalty to the model for being too complex, encouraging it to stay simpler and more general. This way, it’s less likely to make extreme predictions based on the noise in the data."
      ],
      "metadata": {
        "id": "ErNPLHucDZj9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6.**Explain the difference between Lasso, Ridge, and Elastic Net regression"
      ],
      "metadata": {
        "id": "TLwvsAwKDaKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Lasso Regression:-addresses overfitting by adding an L1 penalty (sum of absolute coefficients) to the model’s loss function. This penalty term encourages sparsity by shrinking some coefficients to zero, effectively removing less important features from the model. It is especially useful for feature selection, as it keeps only the most significant predictors.\n",
        "\n",
        "-  Ridge Regression:-is a technique used in linear regression to address the problem of multicollinearity among predictor variables. Multicollinearity occurs when independent variables in a regression model are highly correlated, which can lead to unreliable and unstable estimates of regression coefficients.\n",
        "\n",
        "-  Elastic Net Regression:-combines both L1 (Lasso) and L2 (Ridge) penalties to perform feature selection and manage multicollinearity, balancing coefficient shrinkage and sparsity. This method helps reduce overfitting while retaining all features in the model, making it ideal for datasets with correlated features."
      ],
      "metadata": {
        "id": "RcpDoeOPDiCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7.**When should we use Elastic Net instead of Lasso or Ridge"
      ],
      "metadata": {
        "id": "PsrDjKHbDinO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Elastic Net Regression:-combines both L1 (Lasso) and L2 (Ridge) penalties to perform feature selection and manage multicollinearity, balancing coefficient shrinkage and sparsity. This method helps reduce overfitting while retaining all features in the model, making it ideal for datasets with correlated features."
      ],
      "metadata": {
        "id": "8sMDqYI7D9UJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8.**What is the impact of the regularization parameter (λ) in Logistic Regression"
      ],
      "metadata": {
        "id": "icQJ1XZwD9sk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Through the parameter λ we can control the impact of the regularization term. Higher values lead to smaller coefficients, but too high values for λ can lead to underfitting."
      ],
      "metadata": {
        "id": "_ps8mGB6EDNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9.**What are the key assumptions of Logistic Regression"
      ],
      "metadata": {
        "id": "8S5weOEjEDkI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  The Response Variable is Binary\n",
        "-  The Observations are Independent\n",
        "-  There is No Multicollinearity Among Explanatory Variables\n",
        "-  There are No Extreme Outliers\n",
        "-  There is a Linear Relationship Between Explanatory Variables and the Logit of the Response Variable"
      ],
      "metadata": {
        "id": "27sOaEOmEJul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10.**What are some alternatives to Logistic Regression for classification tasks"
      ],
      "metadata": {
        "id": "_smW6x5nEKHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  A wide range of alternatives are available, from statistics-based procedures (e.g. log binomial, ordinary or modified Poisson regression and Cox regression) to those rooted more deeply in data science such as machine learning and neural network theory."
      ],
      "metadata": {
        "id": "FmVMICqBEPib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11.**What are Classification Evaluation Metrics"
      ],
      "metadata": {
        "id": "49RuMsygEP8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  In a classification task, our main task is to predict the target variable, which is in the form of discrete values."
      ],
      "metadata": {
        "id": "roQBpymDEcyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q12.**How does class imbalance affect Logistic Regression"
      ],
      "metadata": {
        "id": "4UBrJbmlEdS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Imbalanced datasets refer to datasets where the distribution of instances across different classes is skewed or uneven. In other words, one class (the majority class) has significantly more examples than one or more other classes (the minority class or classes)."
      ],
      "metadata": {
        "id": "eb1wpd1tEsPU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13.**What is Hyperparameter Tuning in Logistic Regression"
      ],
      "metadata": {
        "id": "Swzg0cZ_Esux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Machine Learning model is defined as a mathematical model with several parameters that need to be learned from the data. By training a model with existing data we can fit the model parameters. However there is another kind of parameter known as hyperparameters which cannot be directly learned from the regular training process.\n",
        "\n"
      ],
      "metadata": {
        "id": "CrNZBOHpEybB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q14.**What are different solvers in Logistic Regression? Which one should be used"
      ],
      "metadata": {
        "id": "ZsTTbZlHEy89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  The ‘newton-cg’, ‘sag’, and ‘lbfgs’ solvers support only L2 regularization with primal formulation, or no regularization. The ‘liblinear’ solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty."
      ],
      "metadata": {
        "id": "gg3wCyb8E6dV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15.**How is Logistic Regression extended for multiclass classification"
      ],
      "metadata": {
        "id": "1k75dWdXE62S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Multiclass logistic regression emerges as a formidable method in the realm of predictive analytics, adept at handling more complex classifications involving several categories. Indeed, logistic regression can adeptly manage multiclass classification challenges."
      ],
      "metadata": {
        "id": "gvMMcjXpFEbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q16.**What are the advantages and disadvantages of Logistic Regression"
      ],
      "metadata": {
        "id": "YW5ejNRqFE9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Advantages**\n",
        "-  Logistic regression is easier to implement, interpret, and very efficient to train.\n",
        "- It makes no assumptions about distributions of classes in feature space.\n",
        "-  It is very fast at classifying unknown records.\n",
        "\n",
        "**Disadvantages**\n",
        "-  If the number of observations is lesser than the number of features, Logistic Regression should not be used, otherwise, it may lead to overfitting.\n",
        "-  It constructs linear boundaries.\n",
        "-  Logistic Regression requires average or no multicollinearity between independent variables.\n",
        "\n"
      ],
      "metadata": {
        "id": "d47DbpgHFMsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q17.**What are some use cases of Logistic Regression"
      ],
      "metadata": {
        "id": "i4MRUMxCFNES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Medical researchers want to know how exercise and weight impact the probability of having a heart attack. To understand the relationship between the predictor variables and the probability of having a heart attack, researchers can perform logistic regression.\n",
        "-  A business wants to know whether word count and country of origin impact the probability that an email is spam. To understand the relationship between these two predictor variables and the probability of an email being spam, researchers can perform logistic regression."
      ],
      "metadata": {
        "id": "pWxVePoUFS6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q18.**What is the difference between Softmax Regression and Logistic Regression"
      ],
      "metadata": {
        "id": "VXRKGcHpFTrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1.\n",
        "-  Logistic regression estimates the parameters of a logistic model (the coefficients in the linear or non linear combinations)."
      ],
      "metadata": {
        "id": "XYwSFzvXFZLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q19.** How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification"
      ],
      "metadata": {
        "id": "JWVuA6UcFZsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  One approach for using binary classification algorithms for multi-classification problems is to split the multi-class classification dataset into multiple binary classification datasets and fit a binary classification model on each. Two different examples of this approach are the One-vs-Rest and One-vs-One strategies."
      ],
      "metadata": {
        "id": "oItIiEG1Fesq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q20.** How do we interpret coefficients in Logistic Regression"
      ],
      "metadata": {
        "id": "XND88V6uFfSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  When we fit a logistic regression model, the coefficients in the model output represent the average change in the log odds of the response variable associated with a one unit increase in the predictor variable."
      ],
      "metadata": {
        "id": "zdx8tecCFpER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PRACTICAL QUESTIONS"
      ],
      "metadata": {
        "id": "mw9pD-TzFp0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.**Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic\n",
        "Regression, and prints the model accuracy"
      ],
      "metadata": {
        "id": "O1lEvM74Ftx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=1)"
      ],
      "metadata": {
        "id": "KZMwD-lrPh37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.**Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1')\n",
        "and print the model accuracyC"
      ],
      "metadata": {
        "id": "wMKx_BoKF6LU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_regression_model = Lasso(alpha = 0.5)\n",
        "lasso_regression_model"
      ],
      "metadata": {
        "id": "8t8kz-B9VPOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_regression_model.fit(X_train, y_train)\n",
        "for i, col_name in enumerate(X_train.columns):\n",
        "    print(f\"The coefficient for {col_name} is {lasso_regression_model.coef_[i]}\")"
      ],
      "metadata": {
        "id": "9Mr0R6w5VkCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.**Write a Python program to train Logistic Regression with L2 regularization (Ridge) using\n",
        "LogisticRegression(penalty='l2'). Print model accuracy and coefficientsC"
      ],
      "metadata": {
        "id": "3L3HpzMZGF4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#regularised model\n",
        "#ridge regression"
      ],
      "metadata": {
        "id": "Oot6LvMTQiX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "ridge_regression_model = Ridge(alpha=0.1)\n",
        "ridge_regression_model\n",
        "#in practical implementation lambda is alpha"
      ],
      "metadata": {
        "id": "iLy4Q4s9VoWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.**Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')C"
      ],
      "metadata": {
        "id": "HP3O3UaQGP6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Elastic net\n",
        "\n",
        "from sklearn.linear_model import ElasticNet\n",
        "elastic_net_model = ElasticNet(alpha = 1, l1_ratio=0.5)\n",
        "elastic_net_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "1Eau2D3DGU4-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "f21a6536-d2d4-4480-dd9b-52102723073b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElasticNet(alpha=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet(alpha=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ElasticNet</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>ElasticNet(alpha=1)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.** Write a Python program to train a Logistic Regression model for multiclass classification using\n",
        "multi_class='ovr'C"
      ],
      "metadata": {
        "id": "TK6WlNsPGVUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set regularization parameter\n",
        "C_value = 1.0  # You can change this value for stronger or weaker regularization\n",
        "\n",
        "# Initialize Logistic Regression model with One-vs-Rest strategy\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear', penalty='l2', C=C_value, max_iter=200)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Multiclass Logistic Regression accuracy (OvR, C={C_value}): {accuracy:.2f}\")\n",
        "\n",
        "# Print the model coefficients\n",
        "print(\"Model coefficients (one row per class):\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "id": "Ek_soYKxGeTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6.**Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic\n",
        "Regression. Print the best parameters and accuracy"
      ],
      "metadata": {
        "id": "lBYCWRZZGe7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Logistic Regression model\n",
        "log_reg = LogisticRegression(solver='liblinear', multi_class='ovr', max_iter=200)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit GridSearch to training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best parameters found:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Best estimator performance on test data\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test accuracy of best model: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "BhtkAbJFGlEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7.**Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the\n",
        "average accuracyC"
      ],
      "metadata": {
        "id": "ZEuetwzYGllk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Set up the Logistic Regression model\n",
        "C_value = 1.0  # Regularization strength (inverse)\n",
        "model = LogisticRegression(penalty='l2', C=C_value, solver='liblinear', multi_class='ovr', max_iter=200)\n",
        "\n",
        "# Set up Stratified K-Fold Cross-Validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation and compute accuracy for each fold\n",
        "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "# Print accuracy scores and average\n",
        "print(\"Accuracy scores for each fold:\", scores)\n",
        "print(f\"Average accuracy using Stratified K-Fold (C={C_value}): {np.mean(scores):.2f}\")\n"
      ],
      "metadata": {
        "id": "7ujq_DiPG4fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8.**Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its\n",
        "accuracy"
      ],
      "metadata": {
        "id": "4cNBuobJG47P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from CSV file\n",
        "# Replace 'your_dataset.csv' with your actual file path\n",
        "df = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Replace with the actual feature and target column names\n",
        "feature_columns = ['feature1', 'feature2', 'feature3']  # Example\n",
        "target_column = 'target'\n",
        "\n",
        "# Split dataset into features (X) and target (y)\n",
        "X = df[feature_columns]\n",
        "y = df[target_column]\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train Logistic Regression model\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "GqnUcDJyHCej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9.**Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in\n",
        "Logistic Regression. Print the best parameters and accuracy"
      ],
      "metadata": {
        "id": "09KG1AU8HC_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = LogisticRegression(max_iter=200, multi_class='ovr')\n",
        "\n",
        "# Define hyperparameter search space\n",
        "param_distributions = {\n",
        "    'C': uniform(loc=0.01, scale=10),  # Try C values between 0.01 and 10\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']  # solvers that support both l1 and l2\n",
        "}\n",
        "\n",
        "# Set up RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    model,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=20,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit RandomizedSearchCV\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best parameters found:\")\n",
        "print(random_search.best_params_)\n",
        "\n",
        "# Evaluate best model on test set\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test accuracy of best model: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "XBXFaDWMHNp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10.**Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy"
      ],
      "metadata": {
        "id": "D97wzfUgHODr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Base Logistic Regression model\n",
        "base_model = LogisticRegression(solver='liblinear', penalty='l2', C=1.0, max_iter=200)\n",
        "\n",
        "# Wrap with One-vs-One strategy\n",
        "ovo_model = OneVsOneClassifier(base_model)\n",
        "\n",
        "# Train the model\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = ovo_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"One-vs-One Logistic Regression accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "vcnC23G-HTEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11.**Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary\n",
        "classification"
      ],
      "metadata": {
        "id": "QEIg9FkRHThM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "# Step 1: Generate synthetic binary classification data\n",
        "X, y = make_classification(n_samples=1000, n_features=10,\n",
        "                           n_classes=2, n_informative=5, random_state=42)\n",
        "\n",
        "# Step 2: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Step 3: Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Step 6: Visualize the confusion matrix\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Predicted 0\", \"Predicted 1\"],\n",
        "            yticklabels=[\"Actual 0\", \"Actual 1\"])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel(\"Actual Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 7: Print classification report (optional)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "mNw4rlRiD6ZU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q12.**Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,\n",
        "Recall, and F1-Score"
      ],
      "metadata": {
        "id": "W48fW3nzHYfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Step 1: Generate synthetic binary classification data\n",
        "X, y = make_classification(n_samples=1000, n_features=10,\n",
        "                           n_classes=2, n_informative=5, random_state=42)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Step 3: Initialize and train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Step 6: Print evaluation results\n",
        "print(\"Model Performance Metrics:\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1-Score:  {f1:.4f}\")\n",
        "\n",
        "# Optional: More detailed metrics\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "9YasM7HTfZgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13.**Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to\n",
        "improve model performance"
      ],
      "metadata": {
        "id": "l8tB30haHe2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 1: Generate imbalanced binary classification data\n",
        "X, y = make_classification(n_samples=1000, n_features=10,\n",
        "                           n_informative=5, n_redundant=0,\n",
        "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
        "\n",
        "# Step 2: Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Step 3: Train Logistic Regression with class_weight='balanced'\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "print(\"Classification Report (with class_weight='balanced'):\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 6: Visualize the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges',\n",
        "            xticklabels=[\"Predicted 0\", \"Predicted 1\"],\n",
        "            yticklabels=[\"Actual 0\", \"Actual 1\"])\n",
        "plt.title(\"Confusion Matrix with Class Weights\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IILFCT2OHjug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q14.**Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and\n",
        "evaluate performance\n"
      ],
      "metadata": {
        "id": "22LbhGQ7HkGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 1: Load Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Step 2: Select relevant features and target\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "df = df[features + ['survived']]\n",
        "\n",
        "# Step 3: Handle missing values\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Step 4: Encode categorical variables\n",
        "df['sex'] = LabelEncoder().fit_transform(df['sex'])       # male=1, female=0\n",
        "df['embarked'] = LabelEncoder().fit_transform(df['embarked'])\n",
        "\n",
        "# Step 5: Define features (X) and target (y)\n",
        "X = df[features]\n",
        "y = df['survived']\n",
        "\n",
        "# Step 6: Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Step 7: Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 8: Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 9: Confusion matrix visualization\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Not Survived', 'Survived'],\n",
        "            yticklabels=['Not Survived', 'Survived'])\n",
        "plt.title(\"Confusion Matrix - Titanic Logistic Regression\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wplc17UAHr8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15.**Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression\n",
        "model. Evaluate its accuracy and compare results with and without scaling"
      ],
      "metadata": {
        "id": "DdGfxbu8HscW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Step 1: Load the Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Step 2: Select features and target\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "df = df[features + ['survived']]\n",
        "\n",
        "# Step 3: Handle missing values\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Step 4: Encode categorical features\n",
        "df['sex'] = LabelEncoder().fit_transform(df['sex'])       # male=1, female=0\n",
        "df['embarked'] = LabelEncoder().fit_transform(df['embarked'])\n",
        "\n",
        "# Step 5: Define feature matrix and target vector\n",
        "X = df[features]\n",
        "y = df['survived']\n",
        "\n",
        "# Step 6: Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# ----------- Model WITHOUT Scaling -----------\n",
        "model_no_scaling = LogisticRegression(max_iter=1000)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "\n",
        "print(\"🔹 Without Feature Scaling:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_no_scaling))\n",
        "print(classification_report(y_test, y_pred_no_scaling))\n",
        "\n",
        "# ----------- Model WITH Scaling -----------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\n🔹 With Feature Scaling (Standardization):\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_scaled))\n",
        "print(classification_report(y_test, y_pred_scaled))\n"
      ],
      "metadata": {
        "id": "brLuqZTpHzbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q16.**Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score"
      ],
      "metadata": {
        "id": "uTHGuHWsHz2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
        "\n",
        "# Step 1: Load Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Step 2: Select features and target\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "df = df[features + ['survived']]\n",
        "\n",
        "# Step 3: Handle missing values\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Step 4: Encode categorical variables\n",
        "df['sex'] = LabelEncoder().fit_transform(df['sex'])       # male=1, female=0\n",
        "df['embarked'] = LabelEncoder().fit_transform(df['embarked'])\n",
        "\n",
        "# Step 5: Define feature matrix and target\n",
        "X = df[features]\n",
        "y = df['survived']\n",
        "\n",
        "# Step 6: Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Step 7: Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 8: Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 9: Predict probabilities for ROC-AUC\n",
        "y_probs = model.predict_proba(X_test_scaled)[:, 1]  # Probabilities for class 1\n",
        "\n",
        "# Step 10: Compute ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "# Optional: Print classification report\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 11: Plot ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve - Logistic Regression on Titanic\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Fr96dcM_IPGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q17.**Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate\n",
        "accuracy"
      ],
      "metadata": {
        "id": "5YWr3XxkIPgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Step 2: Select features and target\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "df = df[features + ['survived']]\n",
        "\n",
        "# Step 3: Handle missing values\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Step 4: Encode categorical variables\n",
        "df['sex'] = LabelEncoder().fit_transform(df['sex'])       # male=1, female=0\n",
        "df['embarked'] = LabelEncoder().fit_transform(df['embarked'])\n",
        "\n",
        "# Step 5: Define features and target\n",
        "X = df[features]\n",
        "y = df['survived']\n",
        "\n",
        "# Step 6: Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Step 7: Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 8: Train Logistic Regression with C=0.5\n",
        "model = LogisticRegression(C=0.5, max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 9: Predict and evaluate\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Step 10: Output accuracy\n",
        "print(f\"Model Accuracy with C=0.5: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "cCsBAB2lIUCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q18.**Write a Python program to train Logistic Regression and identify important features based on model\n",
        "coefficients"
      ],
      "metadata": {
        "id": "Bp79W24mIUmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Step 2: Select relevant features and target\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "df = df[features + ['survived']]\n",
        "\n",
        "# Step 3: Handle missing values\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Step 4: Encode categorical variables\n",
        "df['sex'] = LabelEncoder().fit_transform(df['sex'])       # male=1, female=0\n",
        "df['embarked'] = LabelEncoder().fit_transform(df['embarked'])\n",
        "\n",
        "# Step 5: Define features and target\n",
        "X = df[features]\n",
        "y = df['survived']\n",
        "\n",
        "# Step 6: Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Step 7: Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 8: Train Logistic Regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 9: Extract feature importances (coefficients)\n",
        "coefficients = model.coef_[0]\n",
        "feature_importance = pd.Series(coefficients, index=features).sort_values(key=abs, ascending=False)\n",
        "\n",
        "# Step 10: Display results\n",
        "print(\"🔍 Feature Importance Based on Coefficients:\")\n",
        "print(feature_importance)\n",
        "\n",
        "# Optional: Plot feature importances\n",
        "plt.figure(figsize=(8, 5))\n",
        "feature_importance.plot(kind='barh', color='skyblue')\n",
        "plt.xlabel(\"Coefficient Value\")\n",
        "plt.title(\"Feature Importance (Logistic Regression Coefficients)\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oaH5d6dNIZ0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q19.** Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa\n",
        "Score"
      ],
      "metadata": {
        "id": "MV6JcUFjIaO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import cohen_kappa_score, classification_report\n",
        "\n",
        "# Step 1: Load the Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Step 2: Select features and the target variable\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "df = df[features + ['survived']]\n",
        "\n",
        "# Step 3: Handle missing values\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Step 4: Encode categorical variables\n",
        "df['sex'] = LabelEncoder().fit_transform(df['sex'])       # male=1, female=0\n",
        "df['embarked'] = LabelEncoder().fit_transform(df['embarked'])\n",
        "\n",
        "# Step 5: Prepare feature matrix and target vector\n",
        "X = df[features]\n",
        "y = df['survived']\n",
        "\n",
        "# Step 6: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Step 7: Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 8: Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 9: Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Step 10: Evaluate using Cohen's Kappa Score\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"Cohen's Kappa Score: {kappa_score:.4f}\")\n",
        "\n",
        "# Optional: Show classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "KRqHzLrZIfOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q20.**Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary\n",
        "classificatio:"
      ],
      "metadata": {
        "id": "JQLGMCuXIf3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "# Step 1: Load Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Step 2: Select relevant features and target\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "df = df[features + ['survived']]\n",
        "\n",
        "# Step 3: Handle missing values\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Step 4: Encode categorical variables\n",
        "df['sex'] = LabelEncoder().fit_transform(df['sex'])       # male=1, female=0\n",
        "df['embarked'] = LabelEncoder().fit_transform(df['embarked'])\n",
        "\n",
        "# Step 5: Define features and target\n",
        "X = df[features]\n",
        "y = df['survived']\n",
        "\n",
        "# Step 6: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Step 7: Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 8: Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 9: Predict probabilities for Precision-Recall Curve\n",
        "y_probs = model.predict_proba(X_test_scaled)[:, 1]  # Probability of class 1 (survived)\n",
        "\n",
        "# Step 10: Compute Precision-Recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
        "\n",
        "# Step 11: Compute the area under the Precision-Recall curve (PR AUC)\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"Precision-Recall AUC: {pr_auc:.4f}\")\n",
        "\n",
        "# Step 12: Plot Precision-Recall curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, color='b', label=f'PR Curve (AUC = {pr_auc:.2f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve for Logistic Regression')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JwD6HQFVIkJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q21.**Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare\n",
        "their accuracy"
      ],
      "metadata": {
        "id": "PvY5s94uIkoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Step 2: Select relevant features and target\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "df = df[features + ['survived']]\n",
        "\n",
        "# Step 3: Handle missing values\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Step 4: Encode categorical variables\n",
        "df['sex'] = LabelEncoder().fit_transform(df['sex'])       # male=1, female=0\n",
        "df['embarked'] = LabelEncoder().fit_transform(df['embarked'])\n",
        "\n",
        "# Step 5: Define features and target\n",
        "X = df[features]\n",
        "y = df['survived']\n",
        "\n",
        "# Step 6: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Step 7: Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 8: Train and evaluate Logistic Regression with different solvers\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "accuracy_scores = {}\n",
        "\n",
        "for solver in solvers:\n",
        "    # Initialize the model with the current solver\n",
        "    model = LogisticRegression(solver=solver, max_iter=1000)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions and evaluate accuracy\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Store the accuracy score for comparison\n",
        "    accuracy_scores[solver] = accuracy\n",
        "\n",
        "# Step 9: Display accuracy scores for each solver\n",
        "print(\"Accuracy scores for each solver:\")\n",
        "for solver, accuracy in accuracy_scores.items():\n",
        "    print(f\"Solver: {solver}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "MT7iBarsIpoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q22.**Write a Python program to train Logistic Regression and evaluate its performance using Matthews\n",
        "Correlation Coefficient (MCC)"
      ],
      "metadata": {
        "id": "gry3W3jIIqFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import matthews_corrcoef, classification_report\n",
        "\n",
        "# Step 1: Load Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Step 2: Select relevant features and target\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "df = df[features + ['survived']]\n",
        "\n",
        "# Step 3: Handle missing values\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Step 4: Encode categorical variables\n",
        "df['sex'] = LabelEncoder().fit_transform(df['sex'])       # male=1, female=0\n",
        "df['embarked'] = LabelEncoder().fit_transform(df['embarked'])\n",
        "\n",
        "# Step 5: Define features and target\n",
        "X = df[features]\n",
        "y = df['survived']\n",
        "\n",
        "# Step 6: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Step 7: Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 8: Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 9: Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Step 10: Evaluate using Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n",
        "\n",
        "# Optional: Show classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "wxk4QJrvI3VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q23.**Write a Python program to train Logistic Regression on both raw and standardized data. Compare their\n",
        "accuracy to see the impact of feature scaling"
      ],
      "metadata": {
        "id": "gDtRVL37I3ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Step 2: Select relevant features and target\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "df = df[features + ['survived']]\n",
        "\n",
        "# Step 3: Handle missing values\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Step 4: Encode categorical variables\n",
        "df['sex'] = df['sex'].map({'male': 1, 'female': 0})  # male=1, female=0\n",
        "df['embarked'] = df['embarked'].map({'C': 0, 'Q': 1, 'S': 2})  # C=0, Q=1, S=2\n",
        "\n",
        "# Step 5: Define features and target\n",
        "X = df[features]\n",
        "y = df['survived']\n",
        "\n",
        "# Step 6: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Step 7: Feature scaling (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 8: Train Logistic Regression on Raw Data\n",
        "model_raw = LogisticRegression(max_iter=1000)\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "# Step 9: Train Logistic Regression on Standardized Data\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Step 10: Compare accuracy scores\n",
        "print(f\"Accuracy with Raw Data: {accuracy_raw:.4f}\")\n",
        "print(f\"Accuracy with Standardized Data: {accuracy_scaled:.4f}\")\n"
      ],
      "metadata": {
        "id": "o6iOiXxJI8-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q24.**Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using\n",
        "cross-validation"
      ],
      "metadata": {
        "id": "YKOr9iJHI9XP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Step 2: Select relevant features and target\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "df = df[features + ['survived']]\n",
        "\n",
        "# Step 3: Handle missing values\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].\n"
      ],
      "metadata": {
        "id": "GLxR2DpBJB13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q25.**Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to\n",
        "make predictions."
      ],
      "metadata": {
        "id": "x0mfbkvoJCkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib  # For saving and loading the model\n",
        "\n",
        "# Step 1: Load Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Step 2: Select relevant features and target\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "df = df[features]()\n"
      ],
      "metadata": {
        "id": "O8TkdT78JG8_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}